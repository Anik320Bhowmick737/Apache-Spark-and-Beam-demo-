{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRmtW-RJlu9e",
        "outputId": "f074b16a-9075-4223-bc2c-7ab192e0a00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of available CPU cores: 2\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Get the number of CPU cores\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "\n",
        "print(f\"Number of available CPU cores: {num_cores}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMl6lojvi1fd",
        "outputId": "8aea459a-e1b0-421f-cd4c-4b602bc66cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.master(f\"local[{num_cores}]\")\\\n",
        "          .appName(\"AdultCSVData\")\\\n",
        "          .config(\"spark.executor.memory\", \"8g\") \\\n",
        "          .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8bNZRwnkPW2"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(\"/content/adult.csv\",inferSchema=True,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS1IgQIZleTb",
        "outputId": "b61b50d5-d193-4b45-b722-f837b1906800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "|age|       workclass|fnlwgt|   education|education.num|marital.status|       occupation|  relationship| race|   sex|capital.gain|capital.loss|hours.per.week|native.country|income|\n",
            "+---+----------------+------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "| 90|               ?| 77053|     HS-grad|            9|       Widowed|                ?| Not-in-family|White|Female|           0|        4356|            40| United-States| <=50K|\n",
            "| 82|         Private|132870|     HS-grad|            9|       Widowed|  Exec-managerial| Not-in-family|White|Female|           0|        4356|            18| United-States| <=50K|\n",
            "| 66|               ?|186061|Some-college|           10|       Widowed|                ?|     Unmarried|Black|Female|           0|        4356|            40| United-States| <=50K|\n",
            "| 54|         Private|140359|     7th-8th|            4|      Divorced|Machine-op-inspct|     Unmarried|White|Female|           0|        3900|            40| United-States| <=50K|\n",
            "| 41|         Private|264663|Some-college|           10|     Separated|   Prof-specialty|     Own-child|White|Female|           0|        3900|            40| United-States| <=50K|\n",
            "| 34|         Private|216864|     HS-grad|            9|      Divorced|    Other-service|     Unmarried|White|Female|           0|        3770|            45| United-States| <=50K|\n",
            "| 38|         Private|150601|        10th|            6|     Separated|     Adm-clerical|     Unmarried|White|  Male|           0|        3770|            40| United-States| <=50K|\n",
            "| 74|       State-gov| 88638|   Doctorate|           16| Never-married|   Prof-specialty|Other-relative|White|Female|           0|        3683|            20| United-States|  >50K|\n",
            "| 68|     Federal-gov|422013|     HS-grad|            9|      Divorced|   Prof-specialty| Not-in-family|White|Female|           0|        3683|            40| United-States| <=50K|\n",
            "| 41|         Private| 70037|Some-college|           10| Never-married|     Craft-repair|     Unmarried|White|  Male|           0|        3004|            60|             ?|  >50K|\n",
            "| 45|         Private|172274|   Doctorate|           16|      Divorced|   Prof-specialty|     Unmarried|Black|Female|           0|        3004|            35| United-States|  >50K|\n",
            "| 38|Self-emp-not-inc|164526| Prof-school|           15| Never-married|   Prof-specialty| Not-in-family|White|  Male|           0|        2824|            45| United-States|  >50K|\n",
            "| 52|         Private|129177|   Bachelors|           13|       Widowed|    Other-service| Not-in-family|White|Female|           0|        2824|            20| United-States|  >50K|\n",
            "| 32|         Private|136204|     Masters|           14|     Separated|  Exec-managerial| Not-in-family|White|  Male|           0|        2824|            55| United-States|  >50K|\n",
            "| 51|               ?|172175|   Doctorate|           16| Never-married|                ?| Not-in-family|White|  Male|           0|        2824|            40| United-States|  >50K|\n",
            "| 46|         Private| 45363| Prof-school|           15|      Divorced|   Prof-specialty| Not-in-family|White|  Male|           0|        2824|            40| United-States|  >50K|\n",
            "| 45|         Private|172822|        11th|            7|      Divorced| Transport-moving| Not-in-family|White|  Male|           0|        2824|            76| United-States|  >50K|\n",
            "| 57|         Private|317847|     Masters|           14|      Divorced|  Exec-managerial| Not-in-family|White|  Male|           0|        2824|            50| United-States|  >50K|\n",
            "| 22|         Private|119592|  Assoc-acdm|           12| Never-married|Handlers-cleaners| Not-in-family|Black|  Male|           0|        2824|            40|             ?|  >50K|\n",
            "| 34|         Private|203034|   Bachelors|           13|     Separated|            Sales| Not-in-family|White|  Male|           0|        2824|            50| United-States|  >50K|\n",
            "+---+----------------+------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyZfT-MKpA_9",
        "outputId": "4788fe6c-1224-4a15-be14-376292f28a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- workclass: string (nullable = true)\n",
            " |-- fnlwgt: integer (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- education.num: integer (nullable = true)\n",
            " |-- marital.status: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- relationship: string (nullable = true)\n",
            " |-- race: string (nullable = true)\n",
            " |-- sex: string (nullable = true)\n",
            " |-- capital.gain: integer (nullable = true)\n",
            " |-- capital.loss: integer (nullable = true)\n",
            " |-- hours.per.week: integer (nullable = true)\n",
            " |-- native.country: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb0Z_farn-43",
        "outputId": "a9e10ae2-32d7-4c32-81ea-e379067c36f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+------------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "|age|       workclass|final_weight|   education|education_num|marital_status|       occupation|  relationship| race|   sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
            "+---+----------------+------------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "| 90|               ?|       77053|     HS-grad|            9|       Widowed|                ?| Not-in-family|White|Female|           0|        4356|            40| United-States| <=50K|\n",
            "| 82|         Private|      132870|     HS-grad|            9|       Widowed|  Exec-managerial| Not-in-family|White|Female|           0|        4356|            18| United-States| <=50K|\n",
            "| 66|               ?|      186061|Some-college|           10|       Widowed|                ?|     Unmarried|Black|Female|           0|        4356|            40| United-States| <=50K|\n",
            "| 54|         Private|      140359|     7th-8th|            4|      Divorced|Machine-op-inspct|     Unmarried|White|Female|           0|        3900|            40| United-States| <=50K|\n",
            "| 41|         Private|      264663|Some-college|           10|     Separated|   Prof-specialty|     Own-child|White|Female|           0|        3900|            40| United-States| <=50K|\n",
            "| 34|         Private|      216864|     HS-grad|            9|      Divorced|    Other-service|     Unmarried|White|Female|           0|        3770|            45| United-States| <=50K|\n",
            "| 38|         Private|      150601|        10th|            6|     Separated|     Adm-clerical|     Unmarried|White|  Male|           0|        3770|            40| United-States| <=50K|\n",
            "| 74|       State-gov|       88638|   Doctorate|           16| Never-married|   Prof-specialty|Other-relative|White|Female|           0|        3683|            20| United-States|  >50K|\n",
            "| 68|     Federal-gov|      422013|     HS-grad|            9|      Divorced|   Prof-specialty| Not-in-family|White|Female|           0|        3683|            40| United-States| <=50K|\n",
            "| 41|         Private|       70037|Some-college|           10| Never-married|     Craft-repair|     Unmarried|White|  Male|           0|        3004|            60|             ?|  >50K|\n",
            "| 45|         Private|      172274|   Doctorate|           16|      Divorced|   Prof-specialty|     Unmarried|Black|Female|           0|        3004|            35| United-States|  >50K|\n",
            "| 38|Self-emp-not-inc|      164526| Prof-school|           15| Never-married|   Prof-specialty| Not-in-family|White|  Male|           0|        2824|            45| United-States|  >50K|\n",
            "| 52|         Private|      129177|   Bachelors|           13|       Widowed|    Other-service| Not-in-family|White|Female|           0|        2824|            20| United-States|  >50K|\n",
            "| 32|         Private|      136204|     Masters|           14|     Separated|  Exec-managerial| Not-in-family|White|  Male|           0|        2824|            55| United-States|  >50K|\n",
            "| 51|               ?|      172175|   Doctorate|           16| Never-married|                ?| Not-in-family|White|  Male|           0|        2824|            40| United-States|  >50K|\n",
            "| 46|         Private|       45363| Prof-school|           15|      Divorced|   Prof-specialty| Not-in-family|White|  Male|           0|        2824|            40| United-States|  >50K|\n",
            "| 45|         Private|      172822|        11th|            7|      Divorced| Transport-moving| Not-in-family|White|  Male|           0|        2824|            76| United-States|  >50K|\n",
            "| 57|         Private|      317847|     Masters|           14|      Divorced|  Exec-managerial| Not-in-family|White|  Male|           0|        2824|            50| United-States|  >50K|\n",
            "| 22|         Private|      119592|  Assoc-acdm|           12| Never-married|Handlers-cleaners| Not-in-family|Black|  Male|           0|        2824|            40|             ?|  >50K|\n",
            "| 34|         Private|      203034|   Bachelors|           13|     Separated|            Sales| Not-in-family|White|  Male|           0|        2824|            50| United-States|  >50K|\n",
            "+---+----------------+------------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "renamed_cols = ['age','workclass','final_weight','education','education_num',\n",
        "                'marital_status','occupation','relationship','race','sex','capital_gain',\n",
        "                'capital_loss','hours_per_week','native_country','income']\n",
        "\n",
        "#Rename columns\n",
        "\n",
        "df = df.toDF(*renamed_cols)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TETNZR_U6cVz",
        "outputId": "d34eb3e4-1d42-4506-e883-453a76cfc4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+------------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "|age|       workclass|final_weight|   education|education_num|marital_status|       occupation|  relationship| race|   sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
            "+---+----------------+------------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "| 90|            NULL|       77053|     HS-grad|            9|       Widowed|             NULL| Not-in-family|White|Female|           0|        4356|            40| United-States| <=50K|\n",
            "| 82|         Private|      132870|     HS-grad|            9|       Widowed|  Exec-managerial| Not-in-family|White|Female|           0|        4356|            18| United-States| <=50K|\n",
            "| 66|            NULL|      186061|Some-college|           10|       Widowed|             NULL|     Unmarried|Black|Female|           0|        4356|            40| United-States| <=50K|\n",
            "| 54|         Private|      140359|     7th-8th|            4|      Divorced|Machine-op-inspct|     Unmarried|White|Female|           0|        3900|            40| United-States| <=50K|\n",
            "| 41|         Private|      264663|Some-college|           10|     Separated|   Prof-specialty|     Own-child|White|Female|           0|        3900|            40| United-States| <=50K|\n",
            "| 34|         Private|      216864|     HS-grad|            9|      Divorced|    Other-service|     Unmarried|White|Female|           0|        3770|            45| United-States| <=50K|\n",
            "| 38|         Private|      150601|        10th|            6|     Separated|     Adm-clerical|     Unmarried|White|  Male|           0|        3770|            40| United-States| <=50K|\n",
            "| 74|       State-gov|       88638|   Doctorate|           16| Never-married|   Prof-specialty|Other-relative|White|Female|           0|        3683|            20| United-States|  >50K|\n",
            "| 68|     Federal-gov|      422013|     HS-grad|            9|      Divorced|   Prof-specialty| Not-in-family|White|Female|           0|        3683|            40| United-States| <=50K|\n",
            "| 41|         Private|       70037|Some-college|           10| Never-married|     Craft-repair|     Unmarried|White|  Male|           0|        3004|            60|          NULL|  >50K|\n",
            "| 45|         Private|      172274|   Doctorate|           16|      Divorced|   Prof-specialty|     Unmarried|Black|Female|           0|        3004|            35| United-States|  >50K|\n",
            "| 38|Self-emp-not-inc|      164526| Prof-school|           15| Never-married|   Prof-specialty| Not-in-family|White|  Male|           0|        2824|            45| United-States|  >50K|\n",
            "| 52|         Private|      129177|   Bachelors|           13|       Widowed|    Other-service| Not-in-family|White|Female|           0|        2824|            20| United-States|  >50K|\n",
            "| 32|         Private|      136204|     Masters|           14|     Separated|  Exec-managerial| Not-in-family|White|  Male|           0|        2824|            55| United-States|  >50K|\n",
            "| 51|            NULL|      172175|   Doctorate|           16| Never-married|             NULL| Not-in-family|White|  Male|           0|        2824|            40| United-States|  >50K|\n",
            "| 46|         Private|       45363| Prof-school|           15|      Divorced|   Prof-specialty| Not-in-family|White|  Male|           0|        2824|            40| United-States|  >50K|\n",
            "| 45|         Private|      172822|        11th|            7|      Divorced| Transport-moving| Not-in-family|White|  Male|           0|        2824|            76| United-States|  >50K|\n",
            "| 57|         Private|      317847|     Masters|           14|      Divorced|  Exec-managerial| Not-in-family|White|  Male|           0|        2824|            50| United-States|  >50K|\n",
            "| 22|         Private|      119592|  Assoc-acdm|           12| Never-married|Handlers-cleaners| Not-in-family|Black|  Male|           0|        2824|            40|          NULL|  >50K|\n",
            "| 34|         Private|      203034|   Bachelors|           13|     Separated|            Sales| Not-in-family|White|  Male|           0|        2824|            50| United-States|  >50K|\n",
            "+---+----------------+------------+------------+-------------+--------------+-----------------+--------------+-----+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.replace('?',None).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAWKDw0_qr5M"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, sum, when"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj3Xry082vlB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, sum\n",
        "\n",
        "# List to store results\n",
        "null_counts = []\n",
        "\n",
        "null_counts = [(column, df.filter(col(column).isNull()).count()) for column in df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsw547Xl5DV7",
        "outputId": "fcd7290c-2634-4aff-cd3a-4ad850054960"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 0),\n",
              " ('workclass', 0),\n",
              " ('final_weight', 0),\n",
              " ('education', 0),\n",
              " ('education_num', 0),\n",
              " ('marital_status', 0),\n",
              " ('occupation', 0),\n",
              " ('relationship', 0),\n",
              " ('race', 0),\n",
              " ('sex', 0),\n",
              " ('capital_gain', 0),\n",
              " ('capital_loss', 0),\n",
              " ('hours_per_week', 0),\n",
              " ('native_country', 0),\n",
              " ('income', 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "null_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7dU2VpP4oUG",
        "outputId": "d3b96c72-1143-4ed0-e7aa-dd77c760e912"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 0),\n",
              " ('workclass', 1836),\n",
              " ('final_weight', 0),\n",
              " ('education', 0),\n",
              " ('education_num', 0),\n",
              " ('marital_status', 0),\n",
              " ('occupation', 1843),\n",
              " ('relationship', 0),\n",
              " ('race', 0),\n",
              " ('sex', 0),\n",
              " ('capital_gain', 0),\n",
              " ('capital_loss', 0),\n",
              " ('hours_per_week', 0),\n",
              " ('native_country', 583),\n",
              " ('income', 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import numpy as np\n",
        "df = df.replace('?',None)\n",
        "\n",
        "null_counts = []\n",
        "\n",
        "null_counts = [(column, df.filter(col(column).isNull()).count()) for column in df.columns]\n",
        "null_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXhclImL7QaD",
        "outputId": "707525a4-21e7-4e21-e9c2-117e026022cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- workclass: string (nullable = true)\n",
            " |-- final_weight: integer (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- education_num: integer (nullable = true)\n",
            " |-- marital_status: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- relationship: string (nullable = true)\n",
            " |-- race: string (nullable = true)\n",
            " |-- sex: string (nullable = true)\n",
            " |-- capital_gain: integer (nullable = true)\n",
            " |-- capital_loss: integer (nullable = true)\n",
            " |-- hours_per_week: integer (nullable = true)\n",
            " |-- native_country: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()# So all the categorical columns have null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYZ2lqPA7ZIK"
      },
      "outputs": [],
      "source": [
        "def stratified_split(data,ratios=[0.8,0.2],target_col='income'):\n",
        "  pos_sample = data.filter(col(target_col)=='>50K')\n",
        "  neg_sample = data.filter(col(target_col)=='<=50K')\n",
        "\n",
        "  train_pos, test_pos = pos_sample.randomSplit(ratios, seed=42)\n",
        "  train_neg, test_neg = neg_sample.randomSplit(ratios, seed=42)\n",
        "\n",
        "  train = train_pos.union(train_neg)\n",
        "  test = test_pos.union(test_neg)\n",
        "\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKf9dm5Z9O1F"
      },
      "outputs": [],
      "source": [
        "Train, Test = stratified_split(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uWIAML49Uos",
        "outputId": "fcd86aef-1d95-40bf-8c34-e1d556dee0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6343\n",
            "19798\n"
          ]
        }
      ],
      "source": [
        "print(Train.filter(col('income')=='>50K').count())\n",
        "print(Train.filter(col('income')=='<=50K').count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhBdopJE9isS",
        "outputId": "34e1049c-7f20-458c-f70a-46998dbc1f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1498\n",
            "4922\n"
          ]
        }
      ],
      "source": [
        "print(Test.filter(col('income')=='>50K').count())\n",
        "print(Test.filter(col('income')=='<=50K').count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1Tv98G4_iyz",
        "outputId": "3cc1e892-a224-4796-b93d-04bfcc0cc192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kmodes in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from kmodes) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from kmodes) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from kmodes) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from kmodes) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->kmodes) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install kmodes\n",
        "from kmodes.kprototypes import KPrototypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBuSxlWrBEf5"
      },
      "source": [
        "# Handle Missing Values using KModes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzxgcB8kQCwC"
      },
      "outputs": [],
      "source": [
        "def fillMissingValues(data,num_clusters=3):\n",
        "  \"\"\"\n",
        "  input: Spark Dataframe, num_clusters: for number of clusters in Kprototypes\n",
        "  returns: Spark Dataframe\n",
        "  \"\"\"\n",
        "  pandas_data = data.toPandas()\n",
        "  target = pandas_data.pop('income')\n",
        "\n",
        "  missing_cols = pandas_data.columns[pandas_data.isnull().sum()>0]\n",
        "\n",
        "  print(\"Columns with missing values : \",missing_cols.tolist())\n",
        "\n",
        "  #get the data from missing cols\n",
        "\n",
        "  missing_data_cols = pandas_data[missing_cols]\n",
        "\n",
        "  #drop the missing cols\n",
        "\n",
        "  pandas_data.drop(missing_cols,axis=1,inplace=True)\n",
        "\n",
        "  # get the categorical columns\n",
        "\n",
        "  object_columns = pandas_data.select_dtypes(include=['object']).columns\n",
        "\n",
        "  #get the column indices\n",
        "\n",
        "  object_column_indices = [pandas_data.columns.get_loc(col) for col in object_columns]\n",
        "\n",
        "  print(\"Categorical columns with no missing values : \",object_column_indices)\n",
        "\n",
        "  #print(num_clusters)\n",
        "\n",
        "  kproto = KPrototypes(n_clusters=num_clusters, init='Cao', verbose=1, n_init=1)\n",
        "\n",
        "  # Fit the K-Prototypes model using the entire dataset except the target and the missing columns\n",
        "\n",
        "  clusters = kproto.fit_predict(pandas_data, categorical = object_column_indices)\n",
        "\n",
        "  #print(clusters)\n",
        "\n",
        "\n",
        "  pandas_data['Cluster'] = clusters\n",
        "\n",
        "  #get back the missing column data\n",
        "\n",
        "  pandas_data[missing_cols] = missing_data_cols\n",
        "\n",
        "  for cluster_id in range(num_clusters):\n",
        "    #print(\"Cluster id : \", cluster_id)\n",
        "    cluster_data = pandas_data[pandas_data['Cluster'] == cluster_id]\n",
        "\n",
        "    # Mode for each categorical variable\n",
        "    cluster_modes = cluster_data.mode().iloc[0]\n",
        "\n",
        "    #print(cluster_modes[missing_cols])\n",
        "\n",
        "    # Impute missing values for the cluster\n",
        "    for col in missing_cols:\n",
        "      #print(\"Filling column : \",col)\n",
        "      pandas_data.loc[pandas_data['Cluster'] == cluster_id,col] = pandas_data.loc[pandas_data['Cluster'] == cluster_id, col].fillna(cluster_modes[col])\n",
        "\n",
        "  pandas_data.drop('Cluster',axis=1,inplace=True)\n",
        "\n",
        "  pandas_data['income'] = target\n",
        "\n",
        "  spark_data = spark.createDataFrame(pandas_data)\n",
        "\n",
        "  return spark_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaQ20jZrTyih",
        "outputId": "b5fcddf2-bdd3-4366-a93a-e4e0c51b3863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with missing values :  ['workclass', 'occupation', 'native_country']\n",
            "Categorical columns with no missing values :  [2, 4, 5, 6, 7]\n",
            "Initialization method and algorithm are deterministic. Setting n_init to 1.\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run: 1, iteration: 1/100, moves: 5999, ncost: 52731096858568.47\n",
            "Run: 1, iteration: 2/100, moves: 4042, ncost: 45674819053653.164\n",
            "Run: 1, iteration: 3/100, moves: 3684, ncost: 41419223983623.92\n",
            "Run: 1, iteration: 4/100, moves: 3021, ncost: 38463101092453.51\n",
            "Run: 1, iteration: 5/100, moves: 2354, ncost: 36426631057478.7\n",
            "Run: 1, iteration: 6/100, moves: 1792, ncost: 34793941405268.164\n",
            "Run: 1, iteration: 7/100, moves: 1417, ncost: 33602114931003.293\n",
            "Run: 1, iteration: 8/100, moves: 1014, ncost: 32963487327406.04\n",
            "Run: 1, iteration: 9/100, moves: 781, ncost: 32537824974550.984\n",
            "Run: 1, iteration: 10/100, moves: 627, ncost: 32294451511327.844\n",
            "Run: 1, iteration: 11/100, moves: 513, ncost: 32160631264502.934\n",
            "Run: 1, iteration: 12/100, moves: 346, ncost: 32083426551937.99\n",
            "Run: 1, iteration: 13/100, moves: 258, ncost: 32008747696453.79\n",
            "Run: 1, iteration: 14/100, moves: 267, ncost: 31922788859490.95\n",
            "Run: 1, iteration: 15/100, moves: 252, ncost: 31868559726858.77\n",
            "Run: 1, iteration: 16/100, moves: 189, ncost: 31843261657755.26\n",
            "Run: 1, iteration: 17/100, moves: 195, ncost: 31822574435140.48\n",
            "Run: 1, iteration: 18/100, moves: 160, ncost: 31799815798499.24\n",
            "Run: 1, iteration: 19/100, moves: 185, ncost: 31756346965197.293\n",
            "Run: 1, iteration: 20/100, moves: 120, ncost: 31740267148729.277\n",
            "Run: 1, iteration: 21/100, moves: 78, ncost: 31735493353971.85\n",
            "Run: 1, iteration: 22/100, moves: 75, ncost: 31731523976248.97\n",
            "Run: 1, iteration: 23/100, moves: 78, ncost: 31730066725331.86\n",
            "Run: 1, iteration: 24/100, moves: 52, ncost: 31729308587762.035\n",
            "Run: 1, iteration: 25/100, moves: 51, ncost: 31727912889454.66\n",
            "Run: 1, iteration: 26/100, moves: 57, ncost: 31725110362596.406\n",
            "Run: 1, iteration: 27/100, moves: 33, ncost: 31724043250749.047\n",
            "Run: 1, iteration: 28/100, moves: 24, ncost: 31722899007657.26\n",
            "Run: 1, iteration: 29/100, moves: 14, ncost: 31722232157532.016\n",
            "Run: 1, iteration: 30/100, moves: 13, ncost: 31721946466541.797\n",
            "Run: 1, iteration: 31/100, moves: 3, ncost: 31721920563638.125\n",
            "Run: 1, iteration: 32/100, moves: 3, ncost: 31721916290118.156\n",
            "Run: 1, iteration: 33/100, moves: 1, ncost: 31721915444009.316\n",
            "Run: 1, iteration: 34/100, moves: 4, ncost: 31721901085540.875\n",
            "Run: 1, iteration: 35/100, moves: 21, ncost: 31721760167196.12\n",
            "Run: 1, iteration: 36/100, moves: 32, ncost: 31721401481608.688\n",
            "Run: 1, iteration: 37/100, moves: 42, ncost: 31720857970727.105\n",
            "Run: 1, iteration: 38/100, moves: 43, ncost: 31720376096183.566\n",
            "Run: 1, iteration: 39/100, moves: 33, ncost: 31720055737823.38\n",
            "Run: 1, iteration: 40/100, moves: 38, ncost: 31719644731622.8\n",
            "Run: 1, iteration: 41/100, moves: 57, ncost: 31718777156083.117\n",
            "Run: 1, iteration: 42/100, moves: 57, ncost: 31717866534052.875\n",
            "Run: 1, iteration: 43/100, moves: 52, ncost: 31716776713922.91\n",
            "Run: 1, iteration: 44/100, moves: 51, ncost: 31715966631693.707\n",
            "Run: 1, iteration: 45/100, moves: 47, ncost: 31715356361655.92\n",
            "Run: 1, iteration: 46/100, moves: 39, ncost: 31714876852246.035\n",
            "Run: 1, iteration: 47/100, moves: 38, ncost: 31714415854876.008\n",
            "Run: 1, iteration: 48/100, moves: 43, ncost: 31713797587719.418\n",
            "Run: 1, iteration: 49/100, moves: 82, ncost: 31712042038032.145\n",
            "Run: 1, iteration: 50/100, moves: 99, ncost: 31709092464215.168\n",
            "Run: 1, iteration: 51/100, moves: 91, ncost: 31705946627769.547\n",
            "Run: 1, iteration: 52/100, moves: 168, ncost: 31697174239155.37\n",
            "Run: 1, iteration: 53/100, moves: 158, ncost: 31689886035328.773\n",
            "Run: 1, iteration: 54/100, moves: 125, ncost: 31686239738873.88\n",
            "Run: 1, iteration: 55/100, moves: 96, ncost: 31684191592726.81\n",
            "Run: 1, iteration: 56/100, moves: 66, ncost: 31682842657371.195\n",
            "Run: 1, iteration: 57/100, moves: 64, ncost: 31681645484282.125\n",
            "Run: 1, iteration: 58/100, moves: 30, ncost: 31681394717062.965\n",
            "Run: 1, iteration: 59/100, moves: 10, ncost: 31681359943416.426\n",
            "Run: 1, iteration: 60/100, moves: 4, ncost: 31681354799131.926\n",
            "Run: 1, iteration: 61/100, moves: 3, ncost: 31681352962103.617\n",
            "Run: 1, iteration: 62/100, moves: 0, ncost: 31681352962103.617\n"
          ]
        }
      ],
      "source": [
        "Imputed_Train = fillMissingValues(Train,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMs7V0jFWvy2",
        "outputId": "de74c59d-a198-4947-bc4e-b746ca7d9cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+------------+------------+-------------+------------------+-----------------+--------------+------------------+------+------------+------------+--------------+------------------+------+\n",
            "|age|       workclass|final_weight|   education|education_num|    marital_status|       occupation|  relationship|              race|   sex|capital_gain|capital_loss|hours_per_week|    native_country|income|\n",
            "+---+----------------+------------+------------+-------------+------------------+-----------------+--------------+------------------+------+------------+------------+--------------+------------------+------+\n",
            "| 19|            NULL|      200790|        12th|            8|Married-civ-spouse|             NULL|Other-relative|             White|Female|       15024|           0|            40|     United-States|  >50K|\n",
            "| 19|         Private|      323605|     7th-8th|            4|     Never-married|    Other-service| Not-in-family|             White|  Male|           0|           0|            60|     United-States|  >50K|\n",
            "| 21|         Private|      334618|Some-college|           10|     Never-married|  Protective-serv| Not-in-family|             Black|Female|       99999|           0|            40|     United-States|  >50K|\n",
            "| 21|         Private|      548303|     HS-grad|            9|Married-civ-spouse|   Prof-specialty|     Own-child|             White|  Male|           0|           0|            40|            Mexico|  >50K|\n",
            "| 22|       Local-gov|      164775|     5th-6th|            3|     Never-married|Handlers-cleaners|Other-relative|             White|  Male|           0|           0|            40|         Guatemala|  >50K|\n",
            "| 22|         Private|      119592|  Assoc-acdm|           12|     Never-married|Handlers-cleaners| Not-in-family|             Black|  Male|           0|        2824|            40|              NULL|  >50K|\n",
            "| 22|         Private|      195532|   Bachelors|           13|     Never-married|   Prof-specialty| Not-in-family|             White|Female|        8614|           0|            40|     United-States|  >50K|\n",
            "| 22|         Private|      228306|Some-college|           10| Married-AF-spouse|    Other-service|          Wife|             White|Female|           0|           0|            40|     United-States|  >50K|\n",
            "| 22|         Private|      231053|        11th|            7|Married-civ-spouse|Machine-op-inspct|       Husband|             White|  Male|           0|           0|            70|     United-States|  >50K|\n",
            "| 22|         Private|      233955|   Bachelors|           13|     Never-married|   Prof-specialty| Not-in-family|Amer-Indian-Eskimo|Female|       14344|           0|            40|     United-States|  >50K|\n",
            "| 22|         Private|      401451|Some-college|           10|Married-civ-spouse| Transport-moving|       Husband|             White|  Male|           0|           0|            48|     United-States|  >50K|\n",
            "| 22|Self-emp-not-inc|      202920|     HS-grad|            9|     Never-married|   Prof-specialty|     Unmarried|             White|Female|       99999|           0|            40|Dominican-Republic|  >50K|\n",
            "| 22|Self-emp-not-inc|      214014|Some-college|           10|     Never-married|            Sales|     Own-child|             Black|  Male|       99999|           0|            55|     United-States|  >50K|\n",
            "| 22|       State-gov|      186634|        12th|            8|     Never-married|  Exec-managerial| Not-in-family|             White|  Male|           0|           0|            50|     United-States|  >50K|\n",
            "| 23|       Local-gov|      197918|Some-college|           10|     Never-married|  Protective-serv|     Own-child|             White|  Male|           0|           0|            40|     United-States|  >50K|\n",
            "| 23|         Private|       41721|   Assoc-voc|           11|Married-civ-spouse|     Craft-repair|       Husband|             White|  Male|           0|           0|            55|     United-States|  >50K|\n",
            "| 23|         Private|       44064|Some-college|           10|         Separated|    Other-service| Not-in-family|             White|  Male|           0|        2559|            40|     United-States|  >50K|\n",
            "| 23|         Private|       65481|     HS-grad|            9|Married-civ-spouse|Machine-op-inspct|          Wife|             White|Female|           0|           0|            40|     United-States|  >50K|\n",
            "| 23|         Private|      106957|        11th|            7|     Never-married|     Craft-repair|     Own-child|Asian-Pac-Islander|  Male|       14344|           0|            40|           Vietnam|  >50K|\n",
            "| 23|         Private|      143003|     Masters|           14|Married-civ-spouse|   Prof-specialty|       Husband|Asian-Pac-Islander|  Male|           0|        1887|            50|             India|  >50K|\n",
            "+---+----------------+------------+------------+-------------+------------------+-----------------+--------------+------------------+------+------------+------------+--------------+------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Train.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI25FOjTRaq6",
        "outputId": "2df6aa07-419e-4097-a0c5-44403a1886e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26141 entries, 0 to 26140\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             26141 non-null  int64 \n",
            " 1   final_weight    26141 non-null  int64 \n",
            " 2   education       26141 non-null  object\n",
            " 3   education_num   26141 non-null  int64 \n",
            " 4   marital_status  26141 non-null  object\n",
            " 5   relationship    26141 non-null  object\n",
            " 6   race            26141 non-null  object\n",
            " 7   sex             26141 non-null  object\n",
            " 8   capital_gain    26141 non-null  int64 \n",
            " 9   capital_loss    26141 non-null  int64 \n",
            " 10  hours_per_week  26141 non-null  int64 \n",
            " 11  workclass       26141 non-null  object\n",
            " 12  occupation      26141 non-null  object\n",
            " 13  native_country  26141 non-null  object\n",
            " 14  income          26141 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 3.0+ MB\n"
          ]
        }
      ],
      "source": [
        "Imputed_Train.toPandas().info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7OsC3RmeJeB",
        "outputId": "350af93d-4f43-4282-f0a7-1647fc75dce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+------------+-------------+------------------+--------------+------------------+------+------------+------------+--------------+----------------+-----------------+------------------+------+\n",
            "|age|final_weight|   education|education_num|    marital_status|  relationship|              race|   sex|capital_gain|capital_loss|hours_per_week|       workclass|       occupation|    native_country|income|\n",
            "+---+------------+------------+-------------+------------------+--------------+------------------+------+------------+------------+--------------+----------------+-----------------+------------------+------+\n",
            "| 19|      200790|        12th|            8|Married-civ-spouse|Other-relative|             White|Female|       15024|           0|            40|         Private|     Craft-repair|     United-States|  >50K|\n",
            "| 19|      323605|     7th-8th|            4|     Never-married| Not-in-family|             White|  Male|           0|           0|            60|         Private|    Other-service|     United-States|  >50K|\n",
            "| 21|      334618|Some-college|           10|     Never-married| Not-in-family|             Black|Female|       99999|           0|            40|         Private|  Protective-serv|     United-States|  >50K|\n",
            "| 21|      548303|     HS-grad|            9|Married-civ-spouse|     Own-child|             White|  Male|           0|           0|            40|         Private|   Prof-specialty|            Mexico|  >50K|\n",
            "| 22|      164775|     5th-6th|            3|     Never-married|Other-relative|             White|  Male|           0|           0|            40|       Local-gov|Handlers-cleaners|         Guatemala|  >50K|\n",
            "| 22|      119592|  Assoc-acdm|           12|     Never-married| Not-in-family|             Black|  Male|           0|        2824|            40|         Private|Handlers-cleaners|     United-States|  >50K|\n",
            "| 22|      195532|   Bachelors|           13|     Never-married| Not-in-family|             White|Female|        8614|           0|            40|         Private|   Prof-specialty|     United-States|  >50K|\n",
            "| 22|      228306|Some-college|           10| Married-AF-spouse|          Wife|             White|Female|           0|           0|            40|         Private|    Other-service|     United-States|  >50K|\n",
            "| 22|      231053|        11th|            7|Married-civ-spouse|       Husband|             White|  Male|           0|           0|            70|         Private|Machine-op-inspct|     United-States|  >50K|\n",
            "| 22|      233955|   Bachelors|           13|     Never-married| Not-in-family|Amer-Indian-Eskimo|Female|       14344|           0|            40|         Private|   Prof-specialty|     United-States|  >50K|\n",
            "| 22|      401451|Some-college|           10|Married-civ-spouse|       Husband|             White|  Male|           0|           0|            48|         Private| Transport-moving|     United-States|  >50K|\n",
            "| 22|      202920|     HS-grad|            9|     Never-married|     Unmarried|             White|Female|       99999|           0|            40|Self-emp-not-inc|   Prof-specialty|Dominican-Republic|  >50K|\n",
            "| 22|      214014|Some-college|           10|     Never-married|     Own-child|             Black|  Male|       99999|           0|            55|Self-emp-not-inc|            Sales|     United-States|  >50K|\n",
            "| 22|      186634|        12th|            8|     Never-married| Not-in-family|             White|  Male|           0|           0|            50|       State-gov|  Exec-managerial|     United-States|  >50K|\n",
            "| 23|      197918|Some-college|           10|     Never-married|     Own-child|             White|  Male|           0|           0|            40|       Local-gov|  Protective-serv|     United-States|  >50K|\n",
            "| 23|       41721|   Assoc-voc|           11|Married-civ-spouse|       Husband|             White|  Male|           0|           0|            55|         Private|     Craft-repair|     United-States|  >50K|\n",
            "| 23|       44064|Some-college|           10|         Separated| Not-in-family|             White|  Male|           0|        2559|            40|         Private|    Other-service|     United-States|  >50K|\n",
            "| 23|       65481|     HS-grad|            9|Married-civ-spouse|          Wife|             White|Female|           0|           0|            40|         Private|Machine-op-inspct|     United-States|  >50K|\n",
            "| 23|      106957|        11th|            7|     Never-married|     Own-child|Asian-Pac-Islander|  Male|       14344|           0|            40|         Private|     Craft-repair|           Vietnam|  >50K|\n",
            "| 23|      143003|     Masters|           14|Married-civ-spouse|       Husband|Asian-Pac-Islander|  Male|           0|        1887|            50|         Private|   Prof-specialty|             India|  >50K|\n",
            "+---+------------+------------+-------------+------------------+--------------+------------------+------+------------+------------+--------------+----------------+-----------------+------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Imputed_Train.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33n-uOKpCxCt",
        "outputId": "3688cad3-9b1e-42a2-99ed-f635a990d0f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with missing values :  ['workclass', 'occupation', 'native_country']\n",
            "Categorical columns with no missing values :  [2, 4, 5, 6, 7]\n",
            "Initialization method and algorithm are deterministic. Setting n_init to 1.\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run: 1, iteration: 1/100, moves: 728, ncost: 13076713413180.285\n",
            "Run: 1, iteration: 2/100, moves: 967, ncost: 12220798325446.799\n",
            "Run: 1, iteration: 3/100, moves: 980, ncost: 11326000735296.748\n",
            "Run: 1, iteration: 4/100, moves: 884, ncost: 10487326599892.021\n",
            "Run: 1, iteration: 5/100, moves: 611, ncost: 9968908772815.041\n",
            "Run: 1, iteration: 6/100, moves: 465, ncost: 9513049499696.225\n",
            "Run: 1, iteration: 7/100, moves: 376, ncost: 9073554866282.297\n",
            "Run: 1, iteration: 8/100, moves: 335, ncost: 8728409149643.6\n",
            "Run: 1, iteration: 9/100, moves: 252, ncost: 8520985127761.554\n",
            "Run: 1, iteration: 10/100, moves: 200, ncost: 8408501300061.61\n",
            "Run: 1, iteration: 11/100, moves: 158, ncost: 8329243077159.718\n",
            "Run: 1, iteration: 12/100, moves: 112, ncost: 8278849079585.0\n",
            "Run: 1, iteration: 13/100, moves: 91, ncost: 8260018652210.05\n",
            "Run: 1, iteration: 14/100, moves: 61, ncost: 8250885952831.077\n",
            "Run: 1, iteration: 15/100, moves: 53, ncost: 8246994300999.201\n",
            "Run: 1, iteration: 16/100, moves: 41, ncost: 8242581539746.375\n",
            "Run: 1, iteration: 17/100, moves: 30, ncost: 8238985129021.235\n",
            "Run: 1, iteration: 18/100, moves: 28, ncost: 8233304330432.631\n",
            "Run: 1, iteration: 19/100, moves: 31, ncost: 8216909273630.255\n",
            "Run: 1, iteration: 20/100, moves: 20, ncost: 8214781085250.044\n",
            "Run: 1, iteration: 21/100, moves: 13, ncost: 8214540637964.614\n",
            "Run: 1, iteration: 22/100, moves: 3, ncost: 8214524495475.097\n",
            "Run: 1, iteration: 23/100, moves: 1, ncost: 8214523112157.649\n",
            "Run: 1, iteration: 24/100, moves: 0, ncost: 8214523112157.649\n"
          ]
        }
      ],
      "source": [
        "Imputed_Test = fillMissingValues(Test,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb4zJ9sDC2Ev",
        "outputId": "2e0aa210-3c69-4f68-8d9c-88423629824d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6420 entries, 0 to 6419\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             6420 non-null   int64 \n",
            " 1   final_weight    6420 non-null   int64 \n",
            " 2   education       6420 non-null   object\n",
            " 3   education_num   6420 non-null   int64 \n",
            " 4   marital_status  6420 non-null   object\n",
            " 5   relationship    6420 non-null   object\n",
            " 6   race            6420 non-null   object\n",
            " 7   sex             6420 non-null   object\n",
            " 8   capital_gain    6420 non-null   int64 \n",
            " 9   capital_loss    6420 non-null   int64 \n",
            " 10  hours_per_week  6420 non-null   int64 \n",
            " 11  workclass       6420 non-null   object\n",
            " 12  occupation      6420 non-null   object\n",
            " 13  native_country  6420 non-null   object\n",
            " 14  income          6420 non-null   object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 752.5+ KB\n"
          ]
        }
      ],
      "source": [
        "Imputed_Test.toPandas().info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4IWEr9nBfxy"
      },
      "source": [
        "## Check the class samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "o-9Md6Yk4lzD",
        "outputId": "c8274e92-4aef-4f94-a69a-adcd17a08a71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  income  count\n",
              "0  <=50K  19798\n",
              "1   >50K   6343"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36d11ed6-1676-46d6-98f6-e1b7398351cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>income</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>19798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>6343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36d11ed6-1676-46d6-98f6-e1b7398351cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36d11ed6-1676-46d6-98f6-e1b7398351cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36d11ed6-1676-46d6-98f6-e1b7398351cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e3974208-fe52-4289-b5a2-363a4911d113\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3974208-fe52-4289-b5a2-363a4911d113')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e3974208-fe52-4289-b5a2-363a4911d113 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"Imputed_Train\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \">50K\",\n          \"<=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9514,\n        \"min\": 6343,\n        \"max\": 19798,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6343,\n          19798\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "Imputed_Train.groupby('income').count().toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Bt87dEb7C-1X",
        "outputId": "0e436db9-0671-4bdc-f8cc-49b1378ff655"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  income  count\n",
              "0  <=50K   4922\n",
              "1   >50K   1498"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-810c7d87-d032-4b39-9fef-f8ce68e4d62b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>income</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>4922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&gt;50K</td>\n",
              "      <td>1498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-810c7d87-d032-4b39-9fef-f8ce68e4d62b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-810c7d87-d032-4b39-9fef-f8ce68e4d62b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-810c7d87-d032-4b39-9fef-f8ce68e4d62b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb44e29e-46ac-4e43-91d1-886a47ea0081\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb44e29e-46ac-4e43-91d1-886a47ea0081')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb44e29e-46ac-4e43-91d1-886a47ea0081 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"Imputed_Test\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \">50K\",\n          \"<=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2421,\n        \"min\": 1498,\n        \"max\": 4922,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1498,\n          4922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "Imputed_Test.groupby('income').count().toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV1JfttfH075",
        "outputId": "30100781-cbab-4ed2-f21b-8465cc3115d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: long (nullable = true)\n",
            " |-- final_weight: long (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- education_num: long (nullable = true)\n",
            " |-- marital_status: string (nullable = true)\n",
            " |-- relationship: string (nullable = true)\n",
            " |-- race: string (nullable = true)\n",
            " |-- sex: string (nullable = true)\n",
            " |-- capital_gain: long (nullable = true)\n",
            " |-- capital_loss: long (nullable = true)\n",
            " |-- hours_per_week: long (nullable = true)\n",
            " |-- workclass: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- native_country: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Imputed_Train.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oCpPm1SDBCs",
        "outputId": "a195b91d-ea62-411e-bfad-f8c782430587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['education', 'marital_status', 'relationship', 'race', 'sex', 'workclass', 'occupation', 'native_country', 'income']\n",
            "['age', 'final_weight', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n"
          ]
        }
      ],
      "source": [
        "categorical_cols = []\n",
        "index_categorical_cols = []\n",
        "ohe_categorical_cols = []\n",
        "\n",
        "numerical_cols = []\n",
        "numerical_cols_scaled = []\n",
        "\n",
        "for col, dtype in Imputed_Train.dtypes:\n",
        "  if dtype=='string':\n",
        "    categorical_cols.append(col)\n",
        "    index_categorical_cols.append(col+\"Index\")\n",
        "    ohe_categorical_cols.append(col+\"_ohv\")\n",
        "  else:\n",
        "    numerical_cols.append(col)\n",
        "\n",
        "\n",
        "print(categorical_cols)\n",
        "print(numerical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW6gFn9xIM99"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, MinMaxScaler, VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "indexer = StringIndexer(inputCols=categorical_cols, outputCols=index_categorical_cols)# Apply only string indexer to the income no One Hot encoding\n",
        "encoder = OneHotEncoder(inputCols = indexer.getOutputCols()[:-1], outputCols = ohe_categorical_cols[:-1])\n",
        "vector_assembler_1 = VectorAssembler(inputCols = numerical_cols, outputCol = 'InputFeatures')\n",
        "scaler = MinMaxScaler(inputCol = 'InputFeatures', outputCol = \"ScaledFeatures\")\n",
        "vector_assembler_2 = VectorAssembler(inputCols = [\"ScaledFeatures\"] + encoder.getOutputCols(), outputCol = 'features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PLeipmlIQt0"
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline(stages=[indexer,encoder,vector_assembler_1,scaler, vector_assembler_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWkqSIQYIYYI"
      },
      "outputs": [],
      "source": [
        "model_pipe = pipe.fit(Imputed_Train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpYgz-0MKWSN"
      },
      "outputs": [],
      "source": [
        "Final_Train = model_pipe.transform(Imputed_Train).select('features','incomeIndex')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqSvrXnAd4rG",
        "outputId": "017db72b-d721-41a2-a8be-5e37ea79fdc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+\n",
            "|            features|incomeIndex|\n",
            "+--------------------+-----------+\n",
            "|(97,[0,1,2,3,5,17...|        1.0|\n",
            "|(97,[0,1,2,5,14,2...|        1.0|\n",
            "|(97,[0,1,2,3,5,7,...|        1.0|\n",
            "|(97,[0,1,2,5,6,21...|        1.0|\n",
            "|(97,[0,1,2,5,19,2...|        1.0|\n",
            "|(97,[0,1,2,4,5,12...|        1.0|\n",
            "|(97,[0,1,2,3,5,8,...|        1.0|\n",
            "|(97,[0,1,2,5,7,31...|        1.0|\n",
            "|(97,[0,1,2,5,11,2...|        1.0|\n",
            "|(97,[0,1,2,3,5,8,...|        1.0|\n",
            "|(97,[0,1,2,5,7,21...|        1.0|\n",
            "|(97,[0,1,2,3,5,6,...|        1.0|\n",
            "|(97,[0,1,2,3,5,7,...|        1.0|\n",
            "|(97,[0,1,2,5,17,2...|        1.0|\n",
            "|(97,[0,1,2,5,7,22...|        1.0|\n",
            "|(97,[0,1,2,5,10,2...|        1.0|\n",
            "|(97,[0,1,2,4,5,7,...|        1.0|\n",
            "|(97,[0,1,2,5,6,21...|        1.0|\n",
            "|(97,[0,1,2,3,5,11...|        1.0|\n",
            "|(97,[0,1,2,4,5,9,...|        1.0|\n",
            "+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Final_Train.show()# sparse vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDETgkQ46WlW",
        "outputId": "cff102fc-ef7a-4c76-da5d-2bf3d9ca34d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+\n",
            "|            features|incomeIndex|\n",
            "+--------------------+-----------+\n",
            "|(97,[0,1,2,5,12,2...|        1.0|\n",
            "|(97,[0,1,2,3,5,8,...|        1.0|\n",
            "|(97,[0,1,2,5,7,22...|        1.0|\n",
            "|(97,[0,1,2,5,6,21...|        1.0|\n",
            "|(97,[0,1,2,5,7,21...|        1.0|\n",
            "|(97,[0,1,2,4,5,8,...|        1.0|\n",
            "|(97,[0,1,2,3,5,8,...|        1.0|\n",
            "|(97,[0,1,2,5,6,21...|        1.0|\n",
            "|(97,[0,1,2,5,6,21...|        1.0|\n",
            "|(97,[0,1,2,5,7,21...|        1.0|\n",
            "|(97,[0,1,2,5,11,2...|        1.0|\n",
            "|(97,[0,1,2,5,6,21...|        1.0|\n",
            "|(97,[0,1,2,3,5,7,...|        1.0|\n",
            "|(97,[0,1,2,3,5,8,...|        1.0|\n",
            "|(97,[0,1,2,4,5,8,...|        1.0|\n",
            "|(97,[0,1,2,3,5,10...|        1.0|\n",
            "|(97,[0,1,2,5,6,21...|        1.0|\n",
            "|(97,[0,1,2,5,7,21...|        1.0|\n",
            "|(97,[0,1,2,3,5,8,...|        1.0|\n",
            "|(97,[0,1,2,5,7,21...|        1.0|\n",
            "+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_test = model_pipe.transform(Imputed_Test).select('features','incomeIndex')\n",
        "df_test.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVLzn9GTh6FF"
      },
      "outputs": [],
      "source": [
        "# Check the sparse vector to dense vector\n",
        "from pyspark.ml.linalg import SparseVector, DenseVector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx4r4tfrgfrP",
        "outputId": "a887fc84-cdc2-450e-b2e6-59a6848f71b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(97,[0,1,2,3,5,17,21,32,37,44,57],[0.0273972602739726,0.1280239333885712,0.4666666666666667,0.15024150241502415,0.39795918367346933,1.0,1.0,1.0,1.0,1.0,1.0])\n",
            "\n",
            "\n",
            "\n",
            "[0.02739726 0.12802393 0.46666667 0.1502415  0.         0.39795918\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         1.\n",
            " 0.         0.         0.         1.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         1.         0.         0.         0.\n",
            " 0.         1.         0.         0.         0.         0.\n",
            " 0.         0.         1.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         1.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.        ]\n"
          ]
        }
      ],
      "source": [
        "print(Final_Train.select('features').head()[0])\n",
        "print('\\n\\n')\n",
        "print(DenseVector(Final_Train.select('features').head()[0]).toArray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g0XNgHORhVy"
      },
      "source": [
        "# OverSample the data using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYfex8u3hE7f"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSu1uZyYR7cv"
      },
      "outputs": [],
      "source": [
        "#X_train = Final_Train.select('FinalInputFeatures')\n",
        "X_train = Final_Train.select('features').rdd.map(lambda row: DenseVector(row[0]).toArray()).collect()\n",
        "y_train = np.array(Final_Train.select('incomeIndex').rdd.map(lambda row: row[0]).collect())\n",
        "\n",
        "sm = SMOTE(random_state = 42)\n",
        "X_res,y_res = sm.fit_resample(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-ZSmQryWz8R",
        "outputId": "c1dc7bbf-cd58-4df8-889f-4ff30b384f81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1.]), array([19798, 19798]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "np.unique(y_res,return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zIYK3WzqrFP"
      },
      "source": [
        "# Recreate spark Dataframe to use spark mllib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxh_2JTtn_lP"
      },
      "outputs": [],
      "source": [
        "df_train = map(lambda x,y: (DenseVector(x),int(y)),X_res,y_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVBJiiCcpHdy"
      },
      "outputs": [],
      "source": [
        "df_train = spark.createDataFrame(df_train, schema = ['features','label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cPiTyWM3IAy"
      },
      "source": [
        "# Logistic Regression Benchmark results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG01ajzuraC3",
        "outputId": "7f233408-b6c7-48f9-fb15-e2093d32fb5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.828\n",
            "Train AU-ROC: 0.910\n",
            "Recall for class 0: 0.798 for class 1: 0.798\n",
            "Precision for class 0: 0.850 for class 1: 0.850\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
        "lrModel_benchmark = lr.fit(df_train)\n",
        "print(f\"Train accuracy: {lrModel_benchmark.summary.accuracy:.3f}\")\n",
        "print(f\"Train AU-ROC: {lrModel_benchmark.summary.areaUnderROC:.3f}\")\n",
        "print(f\"Recall for class 0: {lrModel_benchmark.summary.recallByLabel[0]:.3f} for class 1: {lrModel_benchmark.summary.recallByLabel[0]:.3f}\")\n",
        "print(f\"Precision for class 0: {lrModel_benchmark.summary.precisionByLabel[0]:.3f} for class 1: {lrModel_benchmark.summary.precisionByLabel[0]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViY85OJp3RFs"
      },
      "source": [
        "## Check the validation result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pq-mpgbtjc_",
        "outputId": "17940607-893f-4ec2-ca7e-6a625b054014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train F1 score 0.828\n",
            "\n",
            "\n",
            "Test AU-ROC 0.903\n",
            "Test accuracy 0.805\n",
            "Test F1_score 0.817\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "AU_ROC_calc = BinaryClassificationEvaluator(metricName='areaUnderROC',labelCol='label')\n",
        "Accuracy_calc = MulticlassClassificationEvaluator(metricName='accuracy',labelCol='label')\n",
        "F1_calc = MulticlassClassificationEvaluator(metricName='f1')\n",
        "\n",
        "prediction_test = lrModel_benchmark.transform(df_test.withColumnRenamed('incomeIndex','label'))\n",
        "\n",
        "print(f\"Train F1 score {F1_calc.evaluate(lrModel_benchmark.transform(df_train)):.3f}\")\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(f\"Test AU-ROC {AU_ROC_calc.evaluate(prediction_test):.3f}\")\n",
        "print(f\"Test accuracy {Accuracy_calc.evaluate(prediction_test):.3f}\")\n",
        "print(f\"Test F1_score {F1_calc.evaluate(prediction_test):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caxA8jz2n0mw"
      },
      "source": [
        "## Apply Grid Search CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwyLFiSLkd7I"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "lr_tuned = LogisticRegression(featuresCol = 'features', labelCol = 'label')\n",
        "\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(lr_tuned.regParam, [0.01, 0.1, 0.5]) \\\n",
        "    .addGrid(lr_tuned.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .addGrid(lr_tuned.threshold, [0.2,0.5,0.6])\\\n",
        "    .build()\n",
        "\n",
        "\n",
        "crossval = CrossValidator(\n",
        "    estimator=lr_tuned,\n",
        "    estimatorParamMaps=paramGrid,\n",
        "    evaluator=AU_ROC_calc,\n",
        "    numFolds=5)\n",
        "\n",
        "cv_lr_Model = crossval.fit(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX6esmGBAie3",
        "outputId": "9eb0d847-d58e-4949-f9d8-0ec8004ff3a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.2}, Metric: 0.9102365791260315\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5}, Metric: 0.9102363992328968\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.6}, Metric: 0.9102341932457451\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.2}, Metric: 0.9102360351790271\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5}, Metric: 0.910235211094847\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.6}, Metric: 0.9102375686332728\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.2}, Metric: 0.9102357686877903\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5}, Metric: 0.9102361802303335\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.6}, Metric: 0.9102371661083432\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.2}, Metric: 0.9102341457599197\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5}, Metric: 0.9102365275483221\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.6}, Metric: 0.9102350843440241\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.2}, Metric: 0.9102347350089774\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5}, Metric: 0.9102347528778459\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.6}, Metric: 0.9102350987643231\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.2}, Metric: 0.9102343519875378\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5}, Metric: 0.910236195301606\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.6}, Metric: 0.9102352832712584\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.2}, Metric: 0.9102359269017517\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5}, Metric: 0.9102384807535708\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.6}, Metric: 0.9102366497397621\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.2}, Metric: 0.9102369175452486\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5}, Metric: 0.910238120724469\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.6}, Metric: 0.9102360429972356\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.2}, Metric: 0.9102359658157242\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5}, Metric: 0.9102359539136626\n",
            "Params: {Param(parent='LogisticRegression_486ff5ef25d2', name='regParam', doc='regularization parameter (>= 0).'): 0.5, Param(parent='LogisticRegression_486ff5ef25d2', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0, Param(parent='LogisticRegression_486ff5ef25d2', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.6}, Metric: 0.9102371965041648\n"
          ]
        }
      ],
      "source": [
        "for params, metric in zip(paramGrid, cv_lr_Model.avgMetrics):\n",
        "    print(f\"Params: {params}, Metric: {metric}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nimGoYI1o3OT",
        "outputId": "f5b02a39-4733-44bb-88d7-0af414356b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters of the Best Model:\n",
            "aggregationDepth: 2\n",
            "elasticNetParam: 0.0\n",
            "family: auto\n",
            "featuresCol: features\n",
            "fitIntercept: True\n",
            "labelCol: label\n",
            "maxBlockSizeInMB: 0.0\n",
            "maxIter: 100\n",
            "predictionCol: prediction\n",
            "probabilityCol: probability\n",
            "rawPredictionCol: rawPrediction\n",
            "regParam: 0.0\n",
            "standardization: True\n",
            "threshold: 0.5\n",
            "tol: 1e-06\n"
          ]
        }
      ],
      "source": [
        "best_model_lr = cv_lr_Model.bestModel\n",
        "\n",
        "# Get the parameters of the best model\n",
        "best_model_params = best_model_lr.extractParamMap()\n",
        "\n",
        "print(\"Parameters of the Best Model:\")\n",
        "for param, value in best_model_params.items():\n",
        "    print(f\"{param.name}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju9yS0RgCKob",
        "outputId": "6775cb4f-e108-45f6-b3db-625be43c535a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.830\n",
            "Train AU-ROC: 0.912\n",
            "Recall for class 0: 0.799 for class 1: 0.799\n",
            "Precision for class 0: 0.851 for class 1: 0.851\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train accuracy: {best_model_lr.summary.accuracy:.3f}\")\n",
        "print(f\"Train AU-ROC: {best_model_lr.summary.areaUnderROC:.3f}\")\n",
        "print(f\"Recall for class 0: {best_model_lr.summary.recallByLabel[0]:.3f} for class 1: {best_model_lr.summary.recallByLabel[0]:.3f}\")\n",
        "print(f\"Precision for class 0: {best_model_lr.summary.precisionByLabel[0]:.3f} for class 1: {best_model_lr.summary.precisionByLabel[0]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyrgS8O6DAlN",
        "outputId": "c02d70be-88c6-4ad1-c9a1-5504feb37930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train F1 score 0.829\n",
            "\n",
            "\n",
            "Test AU-ROC 0.905\n",
            "Test accuracy 0.805\n",
            "Test F1_score 0.817\n"
          ]
        }
      ],
      "source": [
        "prediction_test = best_model_lr.transform(df_test.withColumnRenamed('incomeIndex','label'))\n",
        "\n",
        "print(f\"Train F1 score {F1_calc.evaluate(best_model_lr.transform(df_train)):.3f}\")\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(f\"Test AU-ROC {AU_ROC_calc.evaluate(prediction_test):.3f}\")\n",
        "print(f\"Test accuracy {Accuracy_calc.evaluate(prediction_test):.3f}\")\n",
        "print(f\"Test F1_score {F1_calc.evaluate(prediction_test):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj_bPF7VDprS"
      },
      "source": [
        "## Plot the AU-ROC of train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "8YJtB9W6Dc0n",
        "outputId": "1b7f2f45-091d-4cbd-bb52-ee0f8b72fba7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "roc = best_model_lr.summary.roc.toPandas()\n",
        "plt.plot(roc['FPR'],roc['TPR'])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWdUftTLEeo5"
      },
      "source": [
        "# Decision Tree Classifier benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxljlLaQElt5",
        "outputId": "fa69886f-42f8-4465-a6f5-17d01007fb8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.824\n",
            "Train F1_score: 0.822\n",
            "Train AU-ROC: 0.834\n",
            "\n",
            "\n",
            "Test AU-ROC 0.827\n",
            "Test accuracy 0.764\n",
            "Test F1_score 0.782\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "DT = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label')\n",
        "DT_benchmark = DT.fit(df_train)\n",
        "\n",
        "train_predictions = DT_benchmark.transform(df_train)\n",
        "test_predictions = DT_benchmark.transform(df_test.withColumnRenamed('incomeIndex','label'))\n",
        "\n",
        "print(f\"Train accuracy: {Accuracy_calc.evaluate(train_predictions):.3f}\")\n",
        "print(f\"Train F1_score: {F1_calc.evaluate(train_predictions):.3f}\")\n",
        "print(f\"Train AU-ROC: {AU_ROC_calc.evaluate(train_predictions):.3f}\")\n",
        "#print(f\"Recall for class 0: {DT_benchmark.summary.recallByLabel[0]:.3f} for class 1: {DT_benchmark.summary.recallByLabel[0]:.3f}\")\n",
        "#print(f\"Precision for class 0: {DT_benchmark.summary.precisionByLabel[0]:.3f} for class 1: {DT_benchmark.summary.precisionByLabel[0]:.3f}\")\n",
        "print('\\n')\n",
        "print(f\"Test AU-ROC {AU_ROC_calc.evaluate(test_predictions):.3f}\")\n",
        "print(f\"Test accuracy {Accuracy_calc.evaluate(test_predictions):.3f}\")\n",
        "print(f\"Test F1_score {F1_calc.evaluate(test_predictions):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC-3peUdFYRZ"
      },
      "outputs": [],
      "source": [
        "DT_tuned = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
        "\n",
        "\n",
        "paramGrid = (ParamGridBuilder()\n",
        "    .addGrid(DT_tuned.maxDepth, [5, 10, 15])\n",
        "    .addGrid(DT_tuned.maxBins, [32, 64, 128])\n",
        "    .addGrid(DT_tuned.minInstancesPerNode, [1, 2, 4])\n",
        "    .addGrid(DT_tuned.impurity, ['gini', 'entropy']).build())\n",
        "\n",
        "crossval = CrossValidator(estimator=DT_tuned,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=AU_ROC_calc,\n",
        "                          numFolds=5,\n",
        "                          parallelism=4)\n",
        "\n",
        "cv_DT_Model = crossval.fit(df_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThGUIMs7Kcgn",
        "outputId": "9b1b33e8-2b50-4653-bf20-20c769ef5d6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8029652235338827\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.7767679734907763\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8029211174302325\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.7764720024789148\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8025987551215854\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8003323955528663\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.7991241695742847\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.7699365824677902\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.7994974573022123\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.7843957279110195\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.7988611088527897\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.7848014863560991\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8004155819622388\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.7502827068806487\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8003768187329625\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.7626368203932278\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.7996734182589016\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.7688514437229174\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8138604610863001\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8007508619438921\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8087132026748804\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.80028601294022\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8078443492773945\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.7991502273220068\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.822465545426405\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8270469676528023\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8194872602764031\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8248041427960986\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8191797643576116\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8236183010905197\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8191552258594198\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8265629496920306\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.81664485639611\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8259073121880949\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.815159596815419\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8271472323980189\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8273156436147397\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8353653581185352\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8076047809858439\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8227788249043584\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.7997472367426575\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8206129884500097\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.829103638902642\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8439399552111346\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8124584561337521\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8328247906167461\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.7938684896488715\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 64, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8255885708395511\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8308401838548998\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.847149414361564\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.816539133935849\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 2, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8366846629033058\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}, Metric: 0.8100968364041684\n",
            "Params: {Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='DecisionTreeClassifier_9a02ae462388', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128, Param(parent='DecisionTreeClassifier_9a02ae462388', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 4, Param(parent='DecisionTreeClassifier_9a02ae462388', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}, Metric: 0.8255649404751507\n"
          ]
        }
      ],
      "source": [
        "for params, metric in zip(paramGrid, cv_DT_Model.avgMetrics):\n",
        "    print(f\"Params: {params}, Metric: {metric}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya6PL0vWKpT4",
        "outputId": "65111ee9-1dc5-4b1d-bd02-ac69548ca6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters of the Best Model:\n",
            "cacheNodeIds: False\n",
            "checkpointInterval: 10\n",
            "featuresCol: features\n",
            "impurity: entropy\n",
            "labelCol: label\n",
            "leafCol: \n",
            "maxBins: 128\n",
            "maxDepth: 15\n",
            "maxMemoryInMB: 256\n",
            "minInfoGain: 0.0\n",
            "minInstancesPerNode: 1\n",
            "minWeightFractionPerNode: 0.0\n",
            "predictionCol: prediction\n",
            "probabilityCol: probability\n",
            "rawPredictionCol: rawPrediction\n",
            "seed: 3683280828326119655\n"
          ]
        }
      ],
      "source": [
        "best_model_DT = cv_DT_Model.bestModel\n",
        "\n",
        "# Get the parameters of the best model\n",
        "best_model_params = best_model_DT.extractParamMap()\n",
        "\n",
        "print(\"Parameters of the Best Model:\")\n",
        "for param, value in best_model_params.items():\n",
        "    print(f\"{param.name}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGst1SbcKvnl",
        "outputId": "93d12ba8-4a7a-4d72-aaf5-c218d0219032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.897\n",
            "Train F1_score: 0.897\n",
            "Train AU-ROC: 0.868\n",
            "\n",
            "\n",
            "Test AU-ROC 0.823\n",
            "Test accuracy 0.811\n",
            "Test F1_score 0.821\n"
          ]
        }
      ],
      "source": [
        "train_predictions = best_model_DT.transform(df_train)\n",
        "test_predictions = best_model_DT.transform(df_test.withColumnRenamed('incomeIndex','label'))\n",
        "\n",
        "print(f\"Train accuracy: {Accuracy_calc.evaluate(train_predictions):.3f}\")\n",
        "print(f\"Train F1_score: {F1_calc.evaluate(train_predictions):.3f}\")\n",
        "print(f\"Train AU-ROC: {AU_ROC_calc.evaluate(train_predictions):.3f}\")\n",
        "\n",
        "print('\\n')\n",
        "print(f\"Test AU-ROC {AU_ROC_calc.evaluate(test_predictions):.3f}\")\n",
        "print(f\"Test accuracy {Accuracy_calc.evaluate(test_predictions):.3f}\")\n",
        "print(f\"Test F1_score {F1_calc.evaluate(test_predictions):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VFzvvV8RSDj",
        "outputId": "eb84ed94-62ae-45ca-c28c-7d32813268f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.787\n",
            "Train F1_score: 0.785\n",
            "Train AU-ROC: 0.888\n",
            "\n",
            "\n",
            "Test AU-ROC 0.867\n",
            "Test accuracy 0.722\n",
            "Test F1_score 0.743\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "\n",
        "RF = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
        "RF_benchmark = RF.fit(df_train)\n",
        "\n",
        "train_predictions = RF_benchmark.transform(df_train)\n",
        "test_predictions = RF_benchmark.transform(df_test.withColumnRenamed('incomeIndex','label'))\n",
        "\n",
        "print(f\"Train accuracy: {Accuracy_calc.evaluate(train_predictions):.3f}\")\n",
        "print(f\"Train F1_score: {F1_calc.evaluate(train_predictions):.3f}\")\n",
        "print(f\"Train AU-ROC: {AU_ROC_calc.evaluate(train_predictions):.3f}\")\n",
        "#print(f\"Recall for class 0: {DT_benchmark.summary.recallByLabel[0]:.3f} for class 1: {DT_benchmark.summary.recallByLabel[0]:.3f}\")\n",
        "#print(f\"Precision for class 0: {DT_benchmark.summary.precisionByLabel[0]:.3f} for class 1: {DT_benchmark.summary.precisionByLabel[0]:.3f}\")\n",
        "print('\\n')\n",
        "print(f\"Test AU-ROC {AU_ROC_calc.evaluate(test_predictions):.3f}\")\n",
        "print(f\"Test accuracy {Accuracy_calc.evaluate(test_predictions):.3f}\")\n",
        "print(f\"Test F1_score {F1_calc.evaluate(test_predictions):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17T-Wu3tSVTC"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "AU_ROC_calc = BinaryClassificationEvaluator(metricName='areaUnderROC',labelCol='label')\n",
        "Accuracy_calc = MulticlassClassificationEvaluator(metricName='accuracy',labelCol='label')\n",
        "F1_calc = MulticlassClassificationEvaluator(metricName='f1')\n",
        "\n",
        "RF_tuned = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(RF_tuned.maxDepth, [5, 15]) \\\n",
        "    .addGrid(RF_tuned.numTrees, [20, 50]) \\\n",
        "    .addGrid(RF_tuned.featureSubsetStrategy, ['auto', 'sqrt', 'log2']) \\\n",
        "    .addGrid(RF_tuned.subsamplingRate, [0.6, 0.8]) \\\n",
        "    .build()\n",
        "\n",
        "\n",
        "crossval = CrossValidator(estimator=RF_tuned,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=AU_ROC_calc,\n",
        "                          numFolds=5,\n",
        "                          parallelism=4)\n",
        "\n",
        "cv_RF_Model = crossval.fit(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW_7kaV5VLaG",
        "outputId": "f6ca8eb8-6743-43d7-91ba-db26d936dd60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.8948432300970935\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.8938284505732748\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.894842327117091\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.8938285523067577\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'log2', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.8911904986301172\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'log2', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.8909813016153117\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.8968626952234382\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.8967734596686732\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.89686148054152\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.8967736396723056\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'log2', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.891496917611913\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'log2', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.8947802112914737\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.9333461299404459\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.9337256349345907\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.9333438270037245\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.9337264458376175\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'log2', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.9281447035527363\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'log2', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.9291709904552187\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.9351246100398048\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.9354064375559336\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.9351245094620053\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'sqrt', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.9354067572358848\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'log2', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.6}, Metric: 0.9298207758860958\n",
            "Params: {Param(parent='RandomForestClassifier_8082957fa9f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestClassifier_8082957fa9f3', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_8082957fa9f3', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'log2', Param(parent='RandomForestClassifier_8082957fa9f3', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}, Metric: 0.9304671053711608\n"
          ]
        }
      ],
      "source": [
        "for params, metric in zip(paramGrid, cv_RF_Model.avgMetrics):\n",
        "    print(f\"Params: {params}, Metric: {metric}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK0-cVZYVQgZ",
        "outputId": "537c7821-bfc2-4dab-b82a-61eab53de0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters of the Best Model:\n",
            "bootstrap: True\n",
            "cacheNodeIds: False\n",
            "checkpointInterval: 10\n",
            "featureSubsetStrategy: sqrt\n",
            "featuresCol: features\n",
            "impurity: gini\n",
            "labelCol: label\n",
            "leafCol: \n",
            "maxBins: 32\n",
            "maxDepth: 15\n",
            "maxMemoryInMB: 256\n",
            "minInfoGain: 0.0\n",
            "minInstancesPerNode: 1\n",
            "minWeightFractionPerNode: 0.0\n",
            "numTrees: 50\n",
            "predictionCol: prediction\n",
            "probabilityCol: probability\n",
            "rawPredictionCol: rawPrediction\n",
            "seed: 5024829977650056700\n",
            "subsamplingRate: 0.8\n"
          ]
        }
      ],
      "source": [
        "best_model_RF = cv_RF_Model.bestModel\n",
        "\n",
        "# Get the parameters of the best model\n",
        "best_model_params = best_model_RF.extractParamMap()\n",
        "\n",
        "print(\"Parameters of the Best Model:\")\n",
        "for param, value in best_model_params.items():\n",
        "    print(f\"{param.name}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXmFSYGlVE0U",
        "outputId": "cb70f9c3-0464-4758-dd05-0cecc2be5675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.878\n",
            "Train F1_score: 0.878\n",
            "Train AU-ROC: 0.951\n",
            "\n",
            "\n",
            "Test AU-ROC 0.903\n",
            "Test accuracy 0.800\n",
            "Test F1_score 0.812\n"
          ]
        }
      ],
      "source": [
        "train_predictions = best_model_RF.transform(df_train)\n",
        "test_predictions = best_model_RF.transform(df_test.withColumnRenamed('incomeIndex','label'))\n",
        "\n",
        "print(f\"Train accuracy: {Accuracy_calc.evaluate(train_predictions):.3f}\")\n",
        "print(f\"Train F1_score: {F1_calc.evaluate(train_predictions):.3f}\")\n",
        "print(f\"Train AU-ROC: {AU_ROC_calc.evaluate(train_predictions):.3f}\")\n",
        "\n",
        "print('\\n')\n",
        "print(f\"Test AU-ROC {AU_ROC_calc.evaluate(test_predictions):.3f}\")\n",
        "print(f\"Test accuracy {Accuracy_calc.evaluate(test_predictions):.3f}\")\n",
        "print(f\"Test F1_score {F1_calc.evaluate(test_predictions):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let's ensemble and check the model performance"
      ],
      "metadata": {
        "id": "jnWbvAA_ID5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.functions import vector_to_array\n",
        "def extract_proababs(dataframe,name):\n",
        "  return dataframe.select(vector_to_array(\"probability\")[1].alias(name+\"_probs\")).toPandas()"
      ],
      "metadata": {
        "id": "395b6EmRGtoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "import pandas as pd\n",
        "\n",
        "class StackClassifier:\n",
        "  def __init__(self,base_learners):\n",
        "\n",
        "    self.base_learners = base_learners\n",
        "    self.assembler = None\n",
        "\n",
        "  def extract_probabs(self,dataframe,name):\n",
        "    return dataframe.select(vector_to_array(\"probability\")[1].alias(\"probs_\"+str(name))).toPandas()\n",
        "\n",
        "  def intermediate_transform(self,model,i,data):\n",
        "    return self.extract_probabs(model.transform(data),i)\n",
        "\n",
        "  def get_sparkdata(self,combined_pandas_list,label_col):\n",
        "    combined_pandas_data = pd.concat(combined_pandas_list,axis=1)\n",
        "    feature_cols = combined_pandas_data.columns.values\n",
        "    combined_pandas_data['label'] = label_col\n",
        "\n",
        "    spark_dataframe = spark.createDataFrame(combined_pandas_data)\n",
        "\n",
        "    if self.assembler==None:\n",
        "      self.assembler = VectorAssembler(inputCols = feature_cols ,outputCol=\"features\")\n",
        "      transformed = self.assembler.transform(spark_dataframe)\n",
        "    else:\n",
        "      transformed = self.assembler.transform(spark_dataframe)\n",
        "    return transformed\n",
        "\n",
        "\n",
        "  def fit(self, data):\n",
        "    Label = data.select('label').toPandas()\n",
        "    output_pandas_data = []\n",
        "    self.trained_baselearners = []\n",
        "    print(\"Training base models\")\n",
        "    for i,bs in enumerate(self.base_learners):\n",
        "      print(\"Training model number: \",i+1)\n",
        "      model = bs.fit(data)\n",
        "      output_pandas_data.append(self.intermediate_transform(model,i,data))\n",
        "      #print(Accuracy_calc.evaluate(model.transform(data)))\n",
        "      self.trained_baselearners.append(model)\n",
        "\n",
        "    final_data = self.get_sparkdata(output_pandas_data,Label)\n",
        "\n",
        "    self.gbtClassifier = GBTClassifier()\n",
        "    print(\"Training the meta classifier\")\n",
        "    self.gbt_model = self.gbtClassifier.fit(final_data)\n",
        "\n",
        "\n",
        "  def transform(self,data):\n",
        "    Label = data.select('label').toPandas()\n",
        "    output_pandas_data = []\n",
        "    for i,bs in enumerate(self.trained_baselearners):\n",
        "      #print(Accuracy_calc.evaluate(bs.transform(data)))\n",
        "      output_pandas_data.append(self.intermediate_transform(bs,i,data))\n",
        "\n",
        "    final_data = self.get_sparkdata(output_pandas_data,Label)\n",
        "\n",
        "    return self.gbt_model.transform(final_data)\n"
      ],
      "metadata": {
        "id": "bQzyPXxf07Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "base_LR = LogisticRegression(featuresCol = 'features', labelCol = 'label',\n",
        "                             aggregationDepth = 2,\n",
        "                             elasticNetParam = 0.0,\n",
        "                             regParam = 0.0,\n",
        "                             standardization = True,\n",
        "                             threshold =  0.5,\n",
        "                             tol =  1e-06,\n",
        "                             maxIter = 100)\n",
        "\n",
        "base_DT = DecisionTreeClassifier(featuresCol='features', labelCol='label',\n",
        "                                 checkpointInterval = 10, impurity = 'entropy',\n",
        "                                 maxBins = 128, maxDepth = 15, minInstancesPerNode = 1 )\n",
        "\n",
        "base_RF = RandomForestClassifier(featuresCol = 'features', labelCol = 'label',\n",
        "                                 featureSubsetStrategy = 'sqrt', impurity = 'gini', subsamplingRate = 0.8,\n",
        "                                 numTrees = 50, maxDepth = 15)\n",
        "\n",
        "AU_ROC_calc = BinaryClassificationEvaluator(metricName='areaUnderROC',labelCol='label')\n",
        "Accuracy_calc = MulticlassClassificationEvaluator(metricName='accuracy',labelCol='label')\n",
        "F1_calc = MulticlassClassificationEvaluator(metricName='f1')\n",
        "\n",
        "\n",
        "St = StackClassifier([base_LR,base_DT,base_RF])\n",
        "St.fit(df_train)\n",
        "train_predicted = St.transform(df_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5GW-owq-mRC",
        "outputId": "2b4de956-0c05-482b-a746-c1b3418fbc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training base models\n",
            "Training model number:  1\n",
            "Training model number:  2\n",
            "Training model number:  3\n",
            "Training the meta classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Accuracy_calc.evaluate(train_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxAIIn3TGqz_",
        "outputId": "fb57b027-75bd-4d22-fe7a-1f136880f2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9114809576724922"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AU_ROC_calc.evaluate(train_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD6VQQ7uGtaG",
        "outputId": "fc15c9fc-b2c6-4774-b7c1-d47c182fdec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9744343352760345"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F1_calc.evaluate(train_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnReijkFGt-_",
        "outputId": "63c4439f-89b5-4a0e-cf91-6428acd2aeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.911415906885334"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predicted = St.transform(df_test.withColumnRenamed('incomeIndex','label'))"
      ],
      "metadata": {
        "id": "MACrblWrHLhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Accuracy_calc.evaluate(test_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIsrID7FHfOY",
        "outputId": "e439172a-a885-49eb-8ed1-60841d39c378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8186915887850468"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AU_ROC_calc.evaluate(test_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2B6YCzqHh2h",
        "outputId": "be32bfb8-1a1a-4237-85b2-69b246521059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8698303006202498"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F1_calc.evaluate(test_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ0h9dkmHkY-",
        "outputId": "aae60751-070c-464e-d200-cb1bbcf7c6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8267095886863233"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}